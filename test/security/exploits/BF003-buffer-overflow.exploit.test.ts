/**
 * BF003: Buffer Overflow - Exploit Tests
 *
 * Tests that buffer size is checked BEFORE appending chunks,
 * preventing cumulative buffer overflow attacks.
 */

import { describe, it } from 'node:test';
import assert from 'node:assert';
import { createDecodeStream } from '../../../dist/stream/decode-stream.js';

describe('BF003: Buffer Overflow - Exploit Tests', () => {
  describe('Buffer Size Check Timing', () => {
    it('should check buffer size before appending (not after)', () => {
      const stream = createDecodeStream();
      let errorCaught = false;
      let errorDetails = '';

      stream.on('error', (err) => {
        errorCaught = true;
        errorDetails = err.message;
      });

      // Send a single 11MB chunk (exceeds 10MB limit)
      // Fix should catch this BEFORE adding to buffer
      const largeChunk = Buffer.alloc(11 * 1024 * 1024, 'X');
      stream.write(largeChunk);
      stream.end();

      // Give stream time to process
      return new Promise<void>((resolve) => {
        setTimeout(() => {
          assert.ok(errorCaught, 'Should have caught buffer overflow');
          assert.ok(
            errorDetails.includes('Buffer overflow') || errorDetails.includes('exceed'),
            `Error should mention buffer overflow, got: ${errorDetails}`
          );
          resolve();
        }, 100);
      });
    });

    it('should report both current buffer size and chunk size in error', () => {
      const stream = createDecodeStream();
      let errorMessage = '';

      stream.on('error', (err) => {
        errorMessage = err.message;
      });

      // Send chunk that exceeds limit
      stream.write(Buffer.alloc(11 * 1024 * 1024, 'Y'));
      stream.end();

      return new Promise<void>((resolve) => {
        setTimeout(() => {
          // After fix, error should include buffer and chunk sizes
          assert.ok(
            errorMessage.includes('buffer') || errorMessage.includes('chunk'),
            `Error should include size details: ${errorMessage}`
          );
          resolve();
        }, 100);
      });
    });
  });

  describe('Cumulative Overflow Prevention', () => {
    it('should prevent cumulative overflow from many small chunks', () => {
      const stream = createDecodeStream();
      let errorCaught = false;

      stream.on('error', () => {
        errorCaught = true;
      });

      // Send many 1MB chunks to exceed 10MB total
      // With the fix, should be caught when cumulative size approaches limit
      for (let i = 0; i < 15; i++) {
        if (!errorCaught) {
          stream.write(Buffer.alloc(1 * 1024 * 1024, 'Z'));
        }
      }
      stream.end();

      return new Promise<void>((resolve) => {
        setTimeout(() => {
          assert.ok(errorCaught, 'Should catch cumulative overflow');
          resolve();
        }, 200);
      });
    });
  });

  describe('Legitimate Usage', () => {
    it('should allow chunks under the limit', () => {
      const stream = createDecodeStream();
      let errorCaught = false;

      stream.on('error', (err) => {
        errorCaught = true;
        console.error('Unexpected error:', err.message);
      });

      // Send 5MB worth of data (under 10MB limit)
      for (let i = 0; i < 5; i++) {
        stream.write(Buffer.alloc(1 * 1024 * 1024, 'V'));
      }
      stream.end();

      return new Promise<void>((resolve) => {
        setTimeout(() => {
          assert.ok(!errorCaught, 'Should NOT error for legitimate data');
          resolve();
        }, 200);
      });
    });

    it('should process valid TONL data correctly', () => {
      const stream = createDecodeStream();
      const results: any[] = [];
      let errorCaught = false;

      stream.on('data', (data) => {
        results.push(data);
      });

      stream.on('error', (err) => {
        errorCaught = true;
        console.error('Unexpected error:', err.message);
      });

      // Send valid TONL content
      stream.write(Buffer.from('name,age\n'));
      stream.write(Buffer.from('Alice,30\n'));
      stream.write(Buffer.from('\n\n'));
      stream.write(Buffer.from('name,age\n'));
      stream.write(Buffer.from('Bob,25\n'));
      stream.end();

      return new Promise<void>((resolve) => {
        setTimeout(() => {
          assert.ok(!errorCaught, 'Should not error on valid data');
          assert.ok(results.length > 0, 'Should have processed data');
          resolve();
        }, 100);
      });
    });
  });

  describe('Edge Cases', () => {
    it('should handle exactly 10MB (at limit)', () => {
      const stream = createDecodeStream();
      let errorCaught = false;

      stream.on('error', (err) => {
        // Might error if slightly over due to overhead, that's ok
        errorCaught = true;
      });

      // Send exactly 10MB
      stream.write(Buffer.alloc(10 * 1024 * 1024, 'E'));
      stream.end();

      return new Promise<void>((resolve) => {
        setTimeout(() => {
          // At exact limit might be ok or might error (implementation detail)
          // The key is it doesn't hang or crash
          resolve();
        }, 100);
      });
    });

    it('should handle 10MB + 1 byte (just over limit)', () => {
      const stream = createDecodeStream();
      let errorCaught = false;

      stream.on('error', (err) => {
        errorCaught = true;
        assert.ok(err.message.includes('overflow') || err.message.includes('exceed'));
      });

      // Send 10MB + 1 byte
      stream.write(Buffer.alloc((10 * 1024 * 1024) + 1, 'F'));
      stream.end();

      return new Promise<void>((resolve) => {
        setTimeout(() => {
          assert.ok(errorCaught, 'Should catch overflow at 10MB + 1 byte');
          resolve();
        }, 100);
      });
    });
  });
});
